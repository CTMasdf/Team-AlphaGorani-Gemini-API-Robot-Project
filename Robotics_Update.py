# ì¹´ë©”ë¼ë¥¼ í™œìš©í•´ ì‚¬ì§„ì„ ì°ê³  ì‚¬ë¬¼ì„ ì¸ì‹í•˜ëŠ” ê¸°ëŠ¥ê³¼ 
# ì˜ˆ)"ì•ìœ¼ë¡œ 5ì´ˆ ê°”ë‹¤ê°€ ë©ˆì¶°", "ì˜¤ë¥¸ìª½ìœ¼ë¡œ 2ì´ˆ ëŒì•„" ë“±ì˜ ëª…ë ¹ë“¤ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.


import serial
import time
import google.generativeai as genai
import speech_recognition as sr
from gtts import gTTS
import os
import json
import subprocess 
import re # ì •ê·œí‘œí˜„ì‹ ëª¨ë“ˆ ì¶”ê°€
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
# IMPORTANT: API Key is loaded from .env
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit()

genai.configure(api_key=GEMINI_API_KEY)
# ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
model = genai.GenerativeModel("gemini-2.5-flash")

# ------------------- ê²½ë¡œ ë° ìƒìˆ˜ ì„¤ì • -------------------
IMAGE_PATH = "capture.jpg" # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì‚¬ì§„ ì €ì¥
HISTORY_FILE = "conversation_history.json"
WAKE_WORD = "ì•ŒíŒŒ"  
CAMERA_TRIGGER_KEYWORDS = ['ì‚¬ì§„', 'ì¹´ë©”ë¼', 'ì°ì–´', 'ì´¬ì˜']

# ì•„ë‘ì´ë…¸ ëª…ë ¹ í‚¤ì›Œë“œ (ë‹¨ìˆœ í‚¤ì›Œë“œ)
ARDUINO_COMMAND_KEYWORDS = [
    'M_Sunny', 'M_partly_cloudy', 'M_cloudy', 'M_rainy', 'M_sleet', 'M_snowy',
    'forward', 'backward', 'turn_left', 'turn_right', 'stop'
     # ì›€ì§ì„ í‚¤ì›Œë“œëŠ” ì´ì œ TIMED_COMMANDSì—ì„œ ì²˜ë¦¬
]

# ì•„ë‘ì´ë…¸ ëª…ë ¹ í‚¤ì›Œë“œ (ì‹œê°„ ê¸°ë°˜ ì›€ì§ì„ í‚¤ì›Œë“œ)
TIMED_COMMANDS = ['forward', 'backward', 'turn_left', 'turn_right', 'stop'] 

# ------------------- ì´ˆê¸°í™” ë° ì—°ê²° -------------------
def load_conversation_history():
    """ëŒ€í™” ê¸°ë¡ ë¡œë“œ."""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            print("ëŒ€í™” ê¸°ë¡ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ ê¸°ë¡ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
            return []
    return []

def save_conversation_history(history):
    """ëŒ€í™” ê¸°ë¡ ì €ì¥."""
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# ì•„ë‘ì´ë…¸ ì—°ê²°
try:
    # í¬íŠ¸ ì„¤ì •ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ í™•ì¸í•˜ì„¸ìš”.
    arduino = serial.Serial('/dev/ttyACM0', 9600, timeout=1) 
    print("ì•„ë‘ì´ë…¸ ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨: {e}. ì•„ë‘ì´ë…¸ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    arduino = None

time.sleep(2)
conversation_history = load_conversation_history()

# ------------------- STT/TTS (ê¸°ì¡´ê³¼ ë™ì¼) -------------------

def recognize_speech(prompt=None):
    """ë§ˆì´í¬ë¥¼ í†µí•´ ìŒì„±ì„ ì¸ì‹í•©ë‹ˆë‹¤."""
    r = sr.Recognizer()
    with sr.Microphone() as source:
        r.adjust_for_ambient_noise(source)
        if prompt:
            print(prompt)
        try:
            # ìŒì„± ì¸ì‹ ëŒ€ê¸°
            audio = r.listen(source, timeout=5, phrase_time_limit=10)
        except sr.WaitTimeoutError:
            return ""

    try:
        text = r.recognize_google(audio, language="ko-KR")
        print("ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text)
        return text
    except sr.UnknownValueError:
        # ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ""
    except sr.RequestError as e:
        print(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨ (Google API ì˜¤ë¥˜): {e}")
        return ""

def speak_text(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒí•©ë‹ˆë‹¤."""
    print("ì±—ë´‡:", text)
    try:
        tts = gTTS(text=text, lang='ko')
        tts.save("response.mp3")
        # mpg321ì„ ì‚¬ìš©í•˜ì—¬ ì¬ìƒ (ì—ëŸ¬ ë©”ì‹œì§€ ìˆ¨ê¹€) ë° íŒŒì¼ ì‚­ì œ
        os.system("mpg321 -q response.mp3 > /dev/null 2>&1")
        os.remove("response.mp3")
    except Exception as e:
        print(f"âš ï¸ ìŒì„± ì¶œë ¥ ì˜¤ë¥˜ (gTTS ë˜ëŠ” mpg321): {e}")

# ------------------- ì•„ë‘ì´ë…¸ -------------------

def extract_command(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ìˆœ ì•„ë‘ì´ë…¸ ëª…ë ¹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    text_lower = text.lower()
    for keyword in ARDUINO_COMMAND_KEYWORDS:
        if keyword.lower() in text_lower: # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì°¾ê¸°
            return keyword
    return None

def extract_timed_command(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ 'forward 5', 'backward 10'ê³¼ ê°™ì€ ì‹œê°„ ê¸°ë°˜ ëª…ë ¹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (command, duration) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    text_lower = text.lower()
    for cmd in TIMED_COMMANDS:
        # ì •ê·œí‘œí˜„ì‹: 'forward' ë˜ëŠ” 'backward' ë’¤ì— ê³µë°±ì´ ìˆê³ , ê·¸ ë’¤ì— ìˆ«ìê°€ ì˜¤ëŠ” íŒ¨í„´ì„ ì°¾ìŠµë‹ˆë‹¤.
        # ì˜ˆ: "forward 5" -> ('forward', '5')
        match = re.search(rf'\b({cmd})\s+(\d+)\b', text_lower)
        if match:
            command = match.group(1)
            duration = int(match.group(2))
            return command, duration
    return None, None

def send_to_arduino(command):
    """ì•„ë‘ì´ë…¸ë¡œ ëª…ë ¹ì„ ì „ì†¡í•©ë‹ˆë‹¤."""
    if arduino and command:
        try:
            arduino.write((command + '\n').encode('utf-8'))
            print("ì•„ë‘ì´ë…¸ë¡œ ì „ì†¡:", command)
        except Exception as e:
            print("ì•„ë‘ì´ë…¸ ì „ì†¡ ì˜¤ë¥˜:", e)
    elif command:
        print(f"â„¹ï¸ ì•„ë‘ì´ë…¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ëª…ë ¹ '{command}'ë¥¼ ì „ì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ------------------- Gemini API & History (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •) -------------------

def build_prompt(history):
    """ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
    prompt = ""
    for msg in history:
        role = "User" if msg["role"] == "user" else "Chatbot"
        text_content = msg.get('parts', [''])[0] if isinstance(msg.get('parts'), list) else msg.get('parts', '')
        
        if role == "User":
             prompt += f"User: {text_content}\n"
        else:
             prompt += f"Model: {text_content}\n"
    
    # ëª¨ë¸ì˜ ì—­í•  ì •ì˜ (Gemini ì±—ë´‡í•œí…Œ ì‹œê°„ ëª…ë ¹ì„ ì¶œë ¥í•˜ë„ë¡ ëª…ì‹œ) 
    system_instruction = (
        "ë‹¹ì‹ ì€ ë¼ì¦ˆë² ë¦¬ íŒŒì´ ê¸°ë°˜ì˜ ë¡œë´‡ ì œì–´ ì±—ë´‡ì…ë‹ˆë‹¤. "
        "ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤. "
        "ë¡œë´‡ì˜ ì›€ì§ì„ì— ëŒ€í•œ ìš”ì²­(ì˜ˆ: 'ì•ìœ¼ë¡œ ê°€', 'ë’¤ë¡œ 3ì´ˆê°„ ê°€')ì„ ë°›ìœ¼ë©´, "
        "ë‹µë³€ì˜ **ê°€ì¥ ë§ˆì§€ë§‰ ì¤„ì—** íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ íŒŒì‹±í•  ìˆ˜ ìˆë„ë¡ ì •í™•í•œ ëª…ë ¹ì–´ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. "
        
        "**[ì¤‘ìš” ê·œì¹™]**: "
        "1. **ì‹œê°„ ê¸°ë°˜ ì›€ì§ì„ ìš”ì²­**: ì‚¬ìš©ìê°€ '5ì´ˆ ì•ìœ¼ë¡œ'ì²˜ëŸ¼ ì‹œê°„ê³¼ ì›€ì§ì„ì„ ìš”ì²­í•˜ë©´, ëª…ë ¹ì–´ì™€ ì‹œê°„ì„ ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„í•˜ì—¬ ë§ˆì§€ë§‰ ì¤„ì— ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: 'forward 5' ë˜ëŠ” 'backward 3'). "
        "2. **ë‹¨ìˆœ ì´ë™ ìš”ì²­**: 'ì•ìœ¼ë¡œ ê°€'ì™€ ê°™ì´ ì‹œê°„ ì—†ì´ ë‹¨ìˆœ ì´ë™ë§Œ ìš”ì²­í•˜ë©´, 'forward 1'ì²˜ëŸ¼ ê¸°ë³¸ ì‹œê°„(1ì´ˆ)ì„ ì ìš©í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”. "
        "3. **ë‚ ì”¨ ëª…ë ¹ ìš”ì²­**: ë‚ ì”¨ ê´€ë ¨ ìš”ì²­ì„ ë°›ìœ¼ë©´ ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ ì¤„ì— ë‚ ì”¨ ëª…ë ¹ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: M_Sunny). "
        "4. **ë‹¤ë¥¸ ëª¨ë“  ëª…ë ¹**: ë‹¤ë¥¸ ëª¨ë“  ë‹¨ìˆœ ëª…ë ¹(ì˜ˆ: turn_left)ì€ ì‘ë‹µì˜ ë§¨ ë§ˆì§€ë§‰ ì¤„ì— í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ì¶œë ¥í•˜ì„¸ìš”. "
        "5. **ì¶œë ¥ ì˜ˆì‹œ**: "
        "   - 'ë„¤, 5ì´ˆ ë™ì•ˆ ì•ìœ¼ë¡œ ì›€ì§ì¼ê²Œìš”.' \n   **forward 5**"
    )
    
    return system_instruction + "\n" + prompt


def generate_text_response(prompt_text):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        response = model.generate_content(prompt_text)
        return response.text
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë””ë²„ê¹…ì„ ìœ„í•´ ì½˜ì†”ì— ì¶œë ¥
        print(f"âš ï¸ Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ------------------- ì‚¬ì§„ ì´¬ì˜ ë° ë¶„ì„ (ê¸°ì¡´ê³¼ ë™ì¼) -------------------

def take_picture():
    """rpicam-stillì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì§„ì„ ì´¬ì˜í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        print("ğŸ“· ì‚¬ì§„ ì´¬ì˜ ì¤‘...")
        # -t 500ms ë¯¸ë¦¬ë³´ê¸°
        subprocess.run(["rpicam-still", "-t", "500", "-o", IMAGE_PATH], check=True)
        print("âœ… ì‚¬ì§„ ì´¬ì˜ ì™„ë£Œ:", IMAGE_PATH)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ rpicam-still ì‹¤í–‰ ì˜¤ë¥˜: ì¹´ë©”ë¼ ëª¨ë“ˆì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. {e}")
        return False
    except FileNotFoundError:
        print("âŒ 'rpicam-still' ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. libcamera íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return False

def ask_gemini_about_image(user_text):
    """ì €ì¥ëœ ì´ë¯¸ì§€ë¥¼ ì½ì–´ ì§ˆë¬¸ê³¼ í•¨ê»˜ Geminiì— ì „ì†¡í•©ë‹ˆë‹¤."""
    if not os.path.exists(IMAGE_PATH):
        return "ì£„ì†¡í•´ìš”. ì‚¬ì§„ì„ ì°ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    try:
        with open(IMAGE_PATH, "rb") as f:
            image_data = f.read()

        # ì´ë¯¸ì§€ ë°ì´í„°ì™€ ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ì†¡
        contents = [
            user_text,
            {"mime_type": "image/jpeg", "data": image_data}
        ]
        
        # ì´ë¯¸ì§€ ì „ì†¡ ì‹œì—ëŠ” ëŒ€í™” ê¸°ë¡ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  í˜„ì¬ ìš”ì²­ë§Œ ë³´ëƒ…ë‹ˆë‹¤.
        response = model.generate_content(contents)
        return response.text
        
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ------------------- ëª…ë ¹ì–´ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (ì£¼ìš” ìˆ˜ì •) -------------------

def handle_command(user_text):
    """ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³ , ì¹´ë©”ë¼ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    global conversation_history
    answer = ""

    # ì¹´ë©”ë¼ íŠ¸ë¦¬ê±° í™•ì¸
    is_camera_req = any(keyword in user_text for keyword in CAMERA_TRIGGER_KEYWORDS)

    if is_camera_req:
        # ì¹´ë©”ë¼ ì²˜ë¦¬ ë¡œì§ (ì´ ë¶€ë¶„ì€ ì‹œê°„ ëª…ë ¹ê³¼ ë¬´ê´€í•˜ê²Œ ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        print("--- ì¹´ë©”ë¼ ëª…ë ¹ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ---")
        speak_text("ì‚¬ì§„ì„ ì°ê³  ë¶„ì„í• ê²Œìš”.")
        
        # ... (ì¹´ë©”ë¼ ë° ì´ë¯¸ì§€ ë¶„ì„ ë¡œì§)
        if take_picture():
            cleaned_question = user_text
            for keyword in CAMERA_TRIGGER_KEYWORDS:
                cleaned_question = cleaned_question.replace(keyword, '').strip() 
            
            # ì°ì€ ì‚¬ì§„ì— ëŒ€í•´ ì›í•˜ëŠ” ë‹µë³€ì„ ë°›ê¸° ìœ„í•œ ëª…ë ¹
            if not cleaned_question:
                cleaned_question = "ë°©ê¸ˆ ì°ì€ ì‚¬ì§„ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê²Œ 2ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."

            answer = ask_gemini_about_image(cleaned_question)
            conversation_history.append({"role": "user", "parts": [cleaned_question]})
            conversation_history.append({"role": "model", "parts": [answer]})
        else:
            answer = "ì¹´ë©”ë¼ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
    
    else:
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ëŒ€í™”
        conversation_history.append({"role": "user", "parts": [user_text]})
        prompt = build_prompt(conversation_history)
        answer = generate_text_response(prompt) 
        conversation_history.append({"role": "model", "parts": [answer]})
    
    save_conversation_history(conversation_history)

    # 1. ì‹œê°„ ê¸°ë°˜ ëª…ë ¹ì–´ ì¶”ì¶œ ë° ì²˜ë¦¬ (ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„)
    command, duration = extract_timed_command(answer)
    
    if command and duration is not None:
        # Gemini ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ëª…ë ¹ì–´ì™€ ì‹œê°„ì„ ì°¾ì€ ê²½ìš°
        speak_text(answer) # ì±—ë´‡ ì‘ë‹µ ë¨¼ì € ì¶œë ¥
        
        print(f"--- ì‹œê°„ ê¸°ë°˜ ì´ë™ ëª…ë ¹ ê°ì§€: {command}, {duration}ì´ˆ ---")
        
        # 1. ì´ë™ ëª…ë ¹ ì „ì†¡
        send_to_arduino(command)
        
        # 2. ì§€ì •ëœ ì‹œê°„ë§Œí¼ ëŒ€ê¸°
        print(f"â„¹ï¸ {duration}ì´ˆ ë™ì•ˆ ëŒ€ê¸° ì¤‘...")
        time.sleep(duration)
        
        # 3. ì •ì§€ ëª…ë ¹ ì „ì†¡
        send_to_arduino('stop')
        print("ì •ì§€ ëª…ë ¹ ì „ì†¡ ì™„ë£Œ.")
        # ì •ì§€ ë©”ì‹œì§€ëŠ” ìŒì„± ì¶œë ¥í•˜ì§€ ì•ŠìŒ
        
    else:
        # 2. ë‹¨ìˆœ ëª…ë ¹ì–´ ë˜ëŠ” ë‚ ì”¨ ëª…ë ¹ì–´ ì¶”ì¶œ ë° ì²˜ë¦¬
        command = extract_command(answer)
        
        # ì•„ë‘ì´ë…¸ ëª…ë ¹ì€ ì‘ë‹µ í›„ í•œ ë²ˆë§Œ ì „ì†¡
        send_to_arduino(command)
        
        # ì±—ë´‡ ì‘ë‹µ ì¶œë ¥
        speak_text(answer)

# ------------------- ì±—ë´‡ ë©”ì¸ ë£¨í”„ (ê¸°ì¡´ê³¼ ë™ì¼) -------------------

def chat_bot():
    """ë©”ì¸ ì±—ë´‡ ë£¨í”„."""
    print(f"ìŒì„± ê¸°ë°˜ ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. '{WAKE_WORD}'ë¼ê³  ë§í•˜ë©´ ì§ˆë¬¸ì„ ë°›ì„ê²Œìš”.")
    global conversation_history

    while True:
        # í˜¸ì¶œì–´ ì¸ì‹
        trigger = recognize_speech(f"'{WAKE_WORD}'ë¼ê³  ë§í•´ì£¼ì„¸ìš”")
        if WAKE_WORD in trigger:
            speak_text("ì§ˆë¬¸í•˜ì„¸ìš”")
            question = recognize_speech("ì§ˆë¬¸ì„ ë§í•´ì£¼ì„¸ìš”")
            
            if not question:
                continue

            if "ì¢…ë£Œ" in question or "ê·¸ë§Œ" in question:
                speak_text("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê³„ì„¸ìš”!")
                break
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬ (ì¼ë°˜ ëŒ€í™” ë˜ëŠ” ì¹´ë©”ë¼)
            handle_command(question)


if __name__ == "__main__":
    try:
        chat_bot()
    finally:
        print("ì±—ë´‡ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
